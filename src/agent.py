"""
Deep Search Agentä¸»ç±» - LangGraphç‰ˆæœ¬
æ•´åˆLangGraphå›¾ç»“æ„,å®ç°å®Œæ•´çš„æ·±åº¦æœç´¢æµç¨‹
"""

import json
import os
from datetime import datetime
import time
from typing import Optional, Dict, Any

from .llms import OpenAILLM, BaseLLM
from .graph import create_research_graph, AgentState
from .utils import Config, load_config


class DeepSearchAgent:
    """Deep Search Agentä¸»ç±» - ä½¿ç”¨LangGraphå®ç°"""

    def __init__(self, config: Optional[Config] = None):
        """
        åˆå§‹åŒ–Deep Search Agent

        Args:
            config: é…ç½®å¯¹è±¡,å¦‚æœä¸æä¾›åˆ™è‡ªåŠ¨åŠ è½½
        """
        # åŠ è½½é…ç½®
        self.config = config or load_config()

        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        self.llm_client = self._initialize_llm()

        # åˆ›å»ºLangGraphå›¾
        self.graph = create_research_graph()

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.config.output_dir, exist_ok=True)

        print(f"Deep Search Agent å·²åˆå§‹åŒ– (LangGraphç‰ˆæœ¬)")
        print(f"ä½¿ç”¨LLM: {self.llm_client.get_model_info()}")

    def _initialize_llm(self) -> BaseLLM:
        """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯"""
        
        from .llms.openai_llm import OpenAILLM  
      
        # ä½¿ç”¨ OpenAILLM å®¢æˆ·ç«¯,è®¾ç½® base_url æŒ‡å‘ç¡…åŸºæµåŠ¨  
        return OpenAILLM(  
            api_key=self.config.openai_api_key,  # ä½¿ç”¨æ‚¨çš„ç¡…åŸºæµåŠ¨ API Key  
            model_name=self.config.openai_model,  # ä½¿ç”¨ç¡…åŸºæµåŠ¨æ”¯æŒçš„æ¨¡å‹åç§°  
            base_url="https://api.siliconflow.cn/v1"  # ç¡…åŸºæµåŠ¨çš„ API ç«¯ç‚¹  
        )


    from typing import Generator, Dict, Any, Optional   # å¼•å…¥ç”Ÿæˆå™¨ç±»å‹æç¤º
    import time

    def research(
        self,
        query: str,
        save_report: bool = True,
        hot_topic_info: Optional[Dict[str, Any]] = None, 
        *,
        stream_config: Optional[Dict[str, Any]] = None
    ) -> Generator[Dict[str, Any], None, None]:
        """
        æ‰§è¡Œæ·±åº¦ç ”ç©¶ï¼Œä»¥ç”Ÿæˆå™¨æ–¹å¼å®æ—¶è¿”å›èŠ‚ç‚¹è¿›åº¦ä¸æœ€ç»ˆæŠ¥å‘Šã€‚

        Args:
            query: ç ”ç©¶é—®é¢˜
            save_report: æ˜¯å¦ä¿å­˜æŠ¥å‘Š
            stream_config: é€ä¼ ç»™ graph.stream çš„é¢å¤–é…ç½®ï¼ˆå¦‚ debugã€recursion_limitï¼‰

        Yields:
            {"node": èŠ‚ç‚¹å, "state": å½“å‰çŠ¶æ€å¿«ç…§}
            æœ€åä¸€æ¡ä¸º {"node": "completed", "report": æœ€ç»ˆæŠ¥å‘Š}
        """
        start_time = time.time()
        print(f"\n{'='*60}\nå¼€å§‹æ·±åº¦ç ”ç©¶: {query}\n{'='*60}")

        try:
            # 1. åˆå§‹çŠ¶æ€
            initial_state: AgentState = {
                "query": query,
                "hot_topic_info": hot_topic_info,  # ä¼ é€’å®Œæ•´çš„ HotTopic ä¿¡æ¯
                "report_title": "",
                "paragraphs": [],
                "current_paragraph_index": 0,
                "reflection_count": 0,
                "max_reflections": self.config.max_reflections,
                "final_report": None,
                "completed": False,
            }

            print(f"ğŸ¤– [DEBUG] Agentæ¥æ”¶åˆ°çƒ­ç‚¹ä¿¡æ¯: {hot_topic_info}")  

            # 2. é»˜è®¤é…ç½® & æ”¯æŒå¤–éƒ¨é€ä¼ 
            config = {
                "configurable": {
                    "llm_client": self.llm_client,
                    "tavily_api_key": self.config.tavily_api_key,
                    "max_search_results": self.config.max_search_results,
                    "search_timeout": self.config.search_timeout,
                    "max_content_length": self.config.max_content_length,
                    "max_reflections": self.config.max_reflections,
                },
                "recursion_limit": 100,          # é˜²æ­»å¾ªç¯å…œåº•
                "debug": False,                  # é»˜è®¤å…³é—­è°ƒè¯•æ—¥å¿—
            }
            if stream_config:
                config.update(stream_config)

            # 3. æµå¼æ‰§è¡Œ
            print("\næ‰§è¡Œç ”ç©¶å·¥ä½œæµ...")
            final_state = None
            for chunk in self.graph.stream(initial_state, config):
                node_name = next(iter(chunk))   # æ›´å®‰å…¨åœ°å–é”®
                node_output = chunk[node_name]
                final_state = node_output

                yield {"node": node_name, "state": node_output}

            # 4. åå¤„ç†
            if not final_state:
                raise RuntimeError("å·¥ä½œæµæœªäº§ç”Ÿä»»ä½•çŠ¶æ€")

            final_report = final_state.get("final_report")
            if not final_report:
                raise RuntimeError("æœ€ç»ˆæŠ¥å‘Šä¸ºç©ºï¼Œå¯èƒ½å›¾æœªæ­£ç¡®å¡«å…… final_report å­—æ®µ")

            if save_report:
                self._save_report(final_report, query)

            end_time = time.time()
            run_time = end_time - start_time
            print("\næ·±åº¦ç ”ç©¶å®Œæˆï¼")
            print(f"æ€»ç”¨æ—¶: {run_time:.2f} ç§’")
            yield {"node": "completed", "report": final_report, "run_time": run_time}

        except Exception as e:
            print(f"[research] ç ”ç©¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            raise

        

    def _save_report(self, report_content: str, query: str):
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        query_safe = "".join(c for c in query if c.isalnum() or c in (' ', '-', '_')).rstrip()
        query_safe = query_safe.replace(' ', '_')[:30]

        filename = f"deep_search_report_{query_safe}_{timestamp}.md"
        filepath = os.path.join(self.config.output_dir, filename)

        # ä¿å­˜æŠ¥å‘Š
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(report_content)

        print(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {filepath}")

    def get_progress_summary(self) -> Dict[str, Any]:
        """è·å–è¿›åº¦æ‘˜è¦ - LangGraphç‰ˆæœ¬æš‚ä¸æ”¯æŒ"""
        return {
            "message": "LangGraphç‰ˆæœ¬ä½¿ç”¨å†…ç½®æ£€æŸ¥ç‚¹æœºåˆ¶,è¯·ä½¿ç”¨LangGraphçš„çŠ¶æ€æŸ¥è¯¢API"
        }


def create_agent(config_file: Optional[str] = None) -> DeepSearchAgent:
    """
    åˆ›å»ºDeep Search Agentå®ä¾‹çš„ä¾¿æ·å‡½æ•°

    Args:
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„

    Returns:
        DeepSearchAgentå®ä¾‹
    """
    config = load_config(config_file)
    return DeepSearchAgent(config)